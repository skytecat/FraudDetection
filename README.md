# Обнаружение мошеннических транзакций

## Описание проекта

Цель данного проекта — разработка модели машинного обучения для обнаружения мошеннических транзакций по данным кредитных карт. Задача является задачей бинарной классификации, где целевая переменная (`Class`) принимает значение:
- `1` — мошенническая транзакция.
- `0` — легальная транзакция.

Данные представляют собой транзакции, произведенные европейскими держателями кредитных карт в сентябре 2013 года. Особенностью датасета является **сильный дисбаланс классов**: только **492 из 284,807 транзакций (0.172%)** являются мошенническими.

## Содержание датасета

Датасет содержит следующие признаки:
- **V1, V2, ..., V28:** Основные компоненты, полученные с помощью PCA (метод главных компонент). Исходные признаки не раскрываются из соображений конфиденциальности.
- **Time:** Время в секундах, прошедшее между каждой транзакцией и первой транзакцией в датасете.
- **Amount:** Сумма транзакции.
- **Class:** Целевая переменная:
  - `0` — легальная транзакция.
  - `1` — мошенническая транзакция.

## Проблемы и подходы

### Проблема дисбаланса классов
Доля мошеннических транзакций составляет всего **0.172%**, что создает сложности для обучения моделей:
- Модели могут быть склонны к предсказанию мажоритарного класса, игнорируя миноритарный.
- Стандартные метрики, такие как **Accuracy**, становятся ненадежными, так как высокая точность может быть достигнута простым предсказанием мажоритарного класса.

### Подходы к решению
Для работы с дисбалансом классов я использовала следующие методы:
1. **Методы балансировки данных:**
   - **SMOTE (Synthetic Minority Oversampling Technique):** Генерация новых примеров миноритарного класса.
   - **Random Oversampling:** Увеличение числа примеров миноритарного класса за счет дублирования.
   - **Random Undersampling:** Уменьшение числа примеров мажоритарного класса.
2. **Метрики качества:**
     - **Precision (Точность):** Показывает, насколько надёжны положительные предсказания модели. Важна для минимизации ложных срабатываний.
     - **Recall (Полнота):** Оценивает способность модели находить все случаи миноритарного класса (в данном случае, мошенничества). Критична для минимизации пропущенных случаев.
     - **F1-Score:** Гармоническое среднее между Precision и Recall, которое отражает баланс между данными метриками.
     - **AUPRC (Area Under the Precision-Recall Curve):** Основной показатель качества модели в задачах с дисбалансом, поскольку он измеряет способность модели корректно обнаруживать миноритарный класс при различных порогах.

## Используемые модели

1. **Логистическая регрессия**
2. **Случайный лес**

Каждая модель обучается как на исходных данных, так и на данных, преобразованных с помощью методов балансировки.

## Инструкции по запуску

В проекте уже обученные лучшие модели хранятся в директории **`models/`**. Это позволяет использовать их для предсказаний без необходимости повторного обучения. Ниже приведены шаги, которые помогут вам настроить среду и начать работать с сохраненными моделями.

---

### Предварительные требования
Для запуска проекта необходимы следующие библиотеки Python:
```bash
numpy
pandas
matplotlib
seaborn
scikit-learn
imbalanced-learn
```

### Установка зависимостей

1. Склонируйте репозиторий проекта:

2. Установите зависимости из файла `requirements.txt`:
   ```bash
   pip install -r requirements.txt
   ```

---

### Структура проекта

Проект имеет следующую структуру:

```
FraudDetection/
│
├── README.md               # Описание проекта
├── FraudDetection.ipynb    # Ноутбук с анализом и моделями
├── requirements.txt        # Список зависимостей
└── models/                 # Сохраненные модели
    ├── randov_rf_model.joblib  # Random Forest с Random Oversampling
    ├── imb_rf_model.joblib        # Random Forest с несбалансированными данными
    └── smote_rf_model.joblib  # Random Forest с SMOTE
```
---

### Загрузка и использование обученных моделей

Чтобы загрузить и использовать одну из сохраненных моделей, выполните следующие шаги:

#### **Шаг 1: Импортируйте необходимые библиотеки**

```python
import joblib
import numpy as np
import pandas as pd
```

#### **Шаг 2: Загрузите модель**

Загрузите одну из моделей из директории `models/`. Например, Random Forest, обученную на данных, полученных с помощью Random Oversampling:

```python
# Путь к модели
model_path = 'models/randov_rf_model.joblib'

# Загрузка модели
model = joblib.load(model_path)
print("Модель успешно загружена!")
```

#### **Шаг 3: Выполните предсказания**

Используйте загруженную модель для выполнения предсказаний:

```python
# Предсказание классов
predictions = model.predict(data)
print("Predictions:", predictions)

# Вероятности принадлежности к классам
probabilities = model.predict_proba(data)
print("Probabilities:", probabilities)
```

---

### Датасет

Для данного проекта используется датасет **"Credit Card Fraud Detection"**, который содержит транзакции кредитных карт. 

Датасет доступен на Kaggle: [Credit Card Fraud Detection](https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud).

### Запуск ноутбука
1. Скачайте датасет и поместите его в директорию проекта.
2. Откройте ноутбук `FraudDetection.ipynb`.
3. Выполните ячейки для загрузки данных, обучения моделей и оценки их качества.

## Результаты

В рамках проекта были протестированы различные модели и методы балансировки данных для задачи обнаружения мошеннических транзакций. 
У лучших моделей получились следующие результаты:
- Random Forest с Random Oversampling (Precision = 0.97, Recall = 0.73, AUPRC = 0.82)
- Random Forest с несбалансированными данными (Precision = 0.99, Recall = 0.71, AUPRC = 0.82)
- Random Forest с SMOTE (Precision = 0.91, Recall = 0.77, AUPRC = 0.81)

Сравнение с Dummy Model (Baseline):
Модель, которая предсказывает все объекты как положительный класс, показала следующие результаты:
- AUPRC = 0.50, Precision ≈ 0.002, F1 Score ≈ 0.003.
  
Это соответствует случайному угадыванию. Все протестированные модели значительно превзошли Dummy Model, что подтверждает их практическую ценность для задачи обнаружения мошенничества.
